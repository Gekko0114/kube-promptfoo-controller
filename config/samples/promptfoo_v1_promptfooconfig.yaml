apiVersion: promptfoo.promptfoo.x-k8s.io/v1
kind: PromptFooConfig
metadata:
  labels:
    app.kubernetes.io/name: promptfooconfig
    app.kubernetes.io/instance: promptfooconfig-sample
    app.kubernetes.io/part-of: kube-promptfoo-controller
    app.kubernetes.io/managed-by: kustomize
    app.kubernetes.io/created-by: kube-promptfoo-controller
  name: promptfooconfig-sample
spec:
  prompt: |
      # This configuration compares LLM output of 2 prompts x 2 GPT models across 3 test cases.
      # Learn more: https://promptfoo.dev/docs/configuration/guide
      description: 'My first eval'

      prompts:
        - "Write a tweet about {{topic}}"
        - "Write a very concise, funny tweet about {{topic}}"

      providers: [openai:gpt-3.5-turbo-0613, openai:gpt-4]

      tests:
        - vars:
            topic: bananas

        - vars:
            topic: avocado toast
          assert:
            # For more information on assertions, see https://promptfoo.dev/docs/configuration/expected-outputs
            - type: icontains
              value: avocado
            - type: javascript
              value: 1 / (output.length + 1)  # prefer shorter outputs

        - vars:
            topic: new york city
          assert:
            # For more information on model-graded evals, see https://promptfoo.dev/docs/configuration/expected-outputs/model-graded
            - type: model-graded-closedqa
              value: ensure that the output is funny
  schedule: "*/10 * * * *"
  openaiapikey: "sk-*****"
